#! /usr/bin/env python3

import sys, json, struct
import hashlib
import os
import subprocess

# Hardcode the recoll index path
archive_path = os.environ["HOME"] + "/.recollweb/ToIndex"

# Read a message from stdin and decode it.
def getMessage():
  rawLength = sys.stdin.buffer.read(4)
  if len(rawLength) == 0:
      sys.exit(0)
  messageLength = struct.unpack('@I', rawLength)[0]
  message = sys.stdin.buffer.read(messageLength).decode('utf-8')
  return json.loads(message)

def encodeMessage(messageContent):
  encodedContent = json.dumps(messageContent)
  encodedLength = struct.pack('@I', len(encodedContent))
  return {'length': encodedLength, 'content': encodedContent}

# Send an encoded message to stdout
def sendMessage(encodedMessage):
  sys.stdout.buffer.write(encodedMessage['length'])
  sys.stdout.write(encodedMessage['content'])
  sys.stdout.flush()

def archive(message):
  path = archive_path
  url = message["url"]
  name = "firefox-recoll-web-" + hashlib.md5(url.encode('utf-8')).hexdigest()
  html = open(os.path.join(path, name), "w")
  html.write(message["page"])
  html.close()
  meta = open(os.path.join(path, '.' + name), "w")
  meta_content = [url,
                  "WebHistory",
                  message["mime"],
                  "k:_unindex:encoding=" + message["charset"],
                  ""]
  meta.write("\n".join(meta_content))
  meta.close()

# sys.stderr = open(os.environ["HOME"] + "/log/archive.errors", "a")
# Always listen for messages
while True:
  message = getMessage()
  action = message["type"]
  if action == "archive":
    archive(message)
  elif action == "search":
    # Run recoll -t -A -q
    # query = message["query"]
    query = 'bar'
    cmd = ["recoll", "-t", "-m", "rclbes:BGL", query]
    process = subprocess.run(cmd, stdout=subprocess.PIPE)
    stdout = str(process.stdout)
    # Add the result, and send the message back, so the extension can invalidate
    # stale query responses
    message['result'] = stdout
    sendMessage(encodeMessage(message))
